# 初始化的过程

1. 服务器开机由BIOS/UEFI负责检测并初始化DMAR（即VT-d硬件），为其分配相应的物理地址，并且以ACPI表中的DMAR（DMA Remapping Reporting）表的形式告知VT-d硬件的存在。
2. OS启动后加载对应驱动，驱动从ACPI中读取信息。

## BIOS与IOMMU

在服务器启动过程中，bios通过DMAR ACPI 表（DMA Remapping Reporting Structure）来检测iommu硬件，而在remapping structures这个list里面目前支持5种类型信息。

BIOS收集IOMMU相关的信息，通过ACPI中的特定表组织数据，放置在内存中，等操作系统接管硬件后，它会加载驱动，驱动再详细解析ACPI表中的信息。
DMA Remapping Reporting Structure，
- 0：DMA Remapping Hardware unit Definition(DRHD) Structure， 用来描述真实的iommu硬件的结构
- 1: Reserved Memory Region Reporting(RMRR) Structure
- 2: Root Port ATS Capability Reporting(ATSR) Structure
- 3: Remapping Hardware Static Affinity(RHSA)  Structure
- 4: ACPI Name-space Device Declaration(ANDD) Structure
- 5: Soc Integrated Address Tranlation Cache(SATC) Reporting structure
- 5+: Reserve

对应代码宏定义如下：
```C
/* Values for subtable type in struct acpi_dmar_header */
enum acpi_dmar_type {
	ACPI_DMAR_TYPE_HARDWARE_UNIT = 0,
	ACPI_DMAR_TYPE_RESERVED_MEMORY = 1,
	ACPI_DMAR_TYPE_ROOT_ATS = 2,
	ACPI_DMAR_TYPE_HARDWARE_AFFINITY = 3,
	ACPI_DMAR_TYPE_NAMESPACE = 4,
	ACPI_DMAR_TYPE_SATC = 5,
	ACPI_DMAR_TYPE_RESERVED = 6	/* 6 and greater are reserved */
};
```

##  DMA Remapping Reporting Structure


| Field                  | Byte Length | Byte Offset | Description    |
| ---------------------- | ----------- | ----------- | ------------------------------------------------------------ |
| Signature              | 4           | 0           | “DMAR”. Signature for the DMA Remapping Description table.  |
| Length                 | 4           | 4           | Length, in bytes |
| Revision               | 1           | 8           | 1 |
| Checksum               | 1           | 9           | Entire table must sum to zero. |
| OEMID                  | 6           | 10          | OEM ID  |
| OEM Table ID           | 8           | 16          | For DMAR description table, the Table ID is the manufacturer model ID. |
| OEM Revision           | 4           | 24          | OEM Revision of DMAR Table for OEM Table |
| Creator ID             | 4           | 28          | Vendor ID of utility that created the table. |
| Creator Revision       | 4           | 32          | Revision of utility that created the table.   |
| Host Address Width     | 1           | 36          | DMA 物理地址宽度 = HAW +1， 最大可访问的物理地址由该值决定 |
| Flags                  | 1           | 37          | Bit 0: INTR_REMAP， 0表示不支持中断重映射，1表示支持. Bits 1-7:Reserved. |
| Reserved               | 10          | 38          | Reserved (0).  |
| Remapping Structures[] | -           | 48          | 对应真实的DMAR设备结构列表：DMA Remapping Hardware Unit Definition (DRHD) ,  Reserved Memory Region Reporting (RMRR) ， Root Port ATS Capability Reporting (ATSR) |

内核数据结构定义：

```C
struct acpi_table_header {
	char signature[ACPI_NAMESEG_SIZE];	/* ASCII table signature */
	u32 length;		/* Length of table in bytes, including this header */
	u8 revision;		/* ACPI Specification minor version number */
	u8 checksum;		/* To make sum of entire table == 0 */
	char oem_id[ACPI_OEM_ID_SIZE];	/* ASCII OEM identification */
	char oem_table_id[ACPI_OEM_TABLE_ID_SIZE];	/* ASCII OEM table identification */
	u32 oem_revision;	/* OEM revision number */
	char asl_compiler_id[ACPI_NAMESEG_SIZE];	/* ASCII ASL compiler vendor ID */
	u32 asl_compiler_revision;	/* ASL compiler version */
};

struct acpi_table_dmar {
    struct acpi_table_header header;	/* Common ACPI table header */
    u8 width;		/* Host Address Width */
    u8 flags;
    u8 reserved[10];
};

struct acpi_dmar_header {
	u16 type;
	u16 length;
};

```

## DRHD（DMA Remapping Hardware Unit Definition）表
一个DMAR结构体用于唯一定义系统中存在的一个VT-d重定向硬件。其结构体如下所示：

| Field                 | Byte Length | Byte Offset | Description  |
| --------------------- | ----------- | ----------- | ----------------------------- |
| Type                  | 2           | 0           | 0 - DMA Remapping Hardware Unit Definition (DRHD) structure   |
| Length                | 2           | 2           | 16 + size of Device Scope Structure|
| Flags                 | 1           | 4           | Bit 0: INCLUDE_PCI_ALL， 1： DRHD表示除了Device Scope特别制定的设备，该domain都收到该DMAR设备管理（BIOS IOxAPIC HPET）， 0表示该DMAR设备只管理Device Scope中的设备。 Bits 1-7: Reserved. |
| Reserved              | 1           | 5           | Reserved (0).   |
| Segment Number        | 2           | 6           | The PCI Segment associated with this unit.  可以理解为 PCIE中的domain |
| Register Base Address | 8           | 8           | DMAR相关寄存器地址？？？？   |
| Device Scope []       | -           | 16          | 每个Entry可以用来指明一个PCI endpoint device，一个PCI sub-hierarchy，或者其他设备，如I/O xAPIC或者HPET。|

```C
struct acpi_dmar_hardware_unit { // type = 0, hardware unit definition
	struct acpi_dmar_header header;
	u8 flags;
	u8 size;		/* Size of the register set */
	u16 segment;
	u64 address;		/* Register Base Address */
};

struct acpi_dmar_device_scope {
	u8 entry_type; // endpoint/bridge/ioapic/hpet/namespace
	u8 length;
	u16 reserved;
	u8 enumeration_id;
	u8 bus;
};

```

- segment number可以理解为与某个dma remapping unit关联的pci domain；
- device scope也就是每个dmar unit下可以关联不同的设备；
- INCLUDE_PCI_ALL当这个bit被设置上时驱动会扫描pcie bus下面的所有设备并把这些设备跟这个dmar unit 关联起来，如果这个bit没有设置上则驱动需要解析device scope 然后把这个scope下面的设备跟这个dmar unit关联起来。
- register base address它定义一系列的register。

```C
struct dmar_drhd_unit {
        struct list_head list;          /* list of drhd units   */
        struct  acpi_dmar_header *hdr;  /* ACPI header          */
        u64     reg_base_addr;          /* register base address*/
        struct  dmar_dev_scope *devices;/* target device array  */
        int     devices_cnt;            /* target device count  */
        u16     segment;                /* PCI domain           */
        u8      ignored:1;              /* ignore drhd          */
        u8      include_all:1;
        struct intel_iommu *iommu;
}; 

struct intel_iommu {
        void __iomem    *reg; /* Pointer to hardware regs, virtual addr */
        u64             reg_phys; /* physical address of hw register set */
        u64             reg_size; /* size of hw register set */
        u64             cap;
        u64             ecap;
        u32             gcmd; /* Holds TE, EAFL. Don't need SRTP, SFL, WBF */
        raw_spinlock_t  register_lock; /* protect register handling */
        int             seq_id; /* sequence id of the iommu */
        int             agaw; /* agaw of this iommu */
        int             msagaw; /* max sagaw of this iommu */
        unsigned int    irq, pr_irq;
        u16             segment;     /* PCI segment# */
        unsigned char   name[13];    /* Device Name */

#ifdef CONFIG_INTEL_IOMMU
        unsigned long   *domain_ids; /* bitmap of domains */
        struct dmar_domain ***domains; /* ptr to domains */
        spinlock_t      lock; /* protect context, domain ids*/
        struct root_entry *root_entry; /* virtual address */
  .......
 }

```


## RMRR（Reserved Memory Region Reporting）
RMRR表用于表示BIOS或者UEFI为了DMA的使用而保留的一些系统物理内存，这些内存从操作系统的角度来看其属性为Reserved Memory，因为有一些比较传统的设备（比如USB、UMA显卡等）可能会需要用到一些固定的，或者专用的系统内存，这时候就需要BIOS或UEFI为其保留。即保留的内存的范围（Reserved Memory Region Base Address和Reserved Memory Region Limit Address）和针对的物理设备（Segment Number和Device Scope）。

```C
/* 1: Reserved Memory Definition */
struct acpi_dmar_reserved_memory {
	struct acpi_dmar_header header;
	u16 reserved;
	u16 segment;
	u64 base_address;	/* 4K aligned base address */
	u64 end_address;	/* 4K aligned limit address */
    // device scope[]
};

```
## ATSR（Root Port ATS Capability Reporting）表
ATS是Address Translation Services的意思，它是PCIe Capability的一种，用于表示PCIe设备是否支持经过PCIe Root Port翻译过的地址。ATSR表只适用于那种PCIe设备支持Device-TLB的系统中，即PCIe设备带有地址转换加速功能。一个ATSR表表示一个支持ATS功能的PCIe Root-Port，其结构主要包括两方面信息：Segment Number用于定位PCIe Root-Port；Device Scope用于定位位于该PCIe Root-Port下面的设备。

```C
struct acpi_dmar_atsr {
	struct acpi_dmar_header header;
	u8 flags;
	u8 reserved;
	u16 segment;
    // device scope
};
```

## RHSA（Remapping Hardware Status Affinity）表
　　RHSR表适用于NUMA（Non-Uniform Memory）系统（即不同的CPU Socket都可能会单独连接一些内存条，不同的CPU Socket对同一物理内存的访问路径可能是不同的），并且系统中的VT-d重定向硬件分布于不同的Node上。该表用于表示VT-d重定向硬件从属于哪个Domain。

```C
/* 3: Remapping Hardware Static Affinity Structure */
struct acpi_dmar_rhsa {
	struct acpi_dmar_header header;
	u32 reserved;
	u64 base_address;
	u32 proximity_domain;
};
```
## ANDD（ACPI Name-space Device Declaration）表
一个ANDD表用于表示一个以ACPI name-space规则命名，并且可发出DMA请求的设备。ANDD可以和前面提到的Device Scope Entry结合一起时候。
其中ACPI Device Number，相当于在该VT-d硬件管辖范围内的以ACPI name-space规则命名的硬件ID号，前面Device Scope Entry值需要这个ID号，就可以找到该ANDD表，并从该表的ACPI Object Name区域找到具体的设备。

```C
/* 4: ACPI Namespace Device Declaration Structure */

struct acpi_dmar_andd {
	struct acpi_dmar_header header;
	u8 reserved[3];
	u8 device_number;
	char device_name[1];
};
```




## summary

总的来说就是软件看来有几个IOMMU单元，每个单元负责哪些pci设备。

详细见qemu代码build_dmar_q35，
AcpiTableDmar就是DMA Remapping Reporting Structure，它后面就是DRHD，DRHD就是IOMMU硬件单元，DeviceScope紧跟着DRHD，就是这个DRHD负责处理的那些pci设备。如果DRHD支持device iotlb，还要上报ATSR。

重点说一下RMRR，因为以前在HP ProLiant DL360 Gen9机器做DPDK开发时碰到过问题(Device is ineligible for IOMMU domain attach due to platform RMRR requirement)，HP的服务器带外管理和正常的流量共用一个网卡，这个网卡只能把流量DMA到一个firmware规定的物理内存区域(RMRR)，如果不在这个区域firmware就拿不到流量，把这个网卡绑定到vfio-pci后，网卡DMA的目的地址是dpdk进程的虚拟地址，虚拟地址对应着大页内存的物理地址，大概率和firmware上报的RMRR不同，所以vfio-pci就报错不让绑定，解决办法就是升级firmware，在BIOS中disable 网卡shared memory功能。



## IOMMU驱动（硬件厂商：Intel AMD ARM PPC）

IOMMU厂商注册自己的IOMMU硬件的
- detect
- depend
- early_init
- late_init函数。



intel注册了detect_intel_iommu来检测自己的IOMMU，其它函数都为NULL，finish为0表示检测到自己就不用再检测其它IOMMU硬件了。

```C
struct iommu_table_entry {
	initcall_t	detect;
	initcall_t	depend;
	void	(*early_init)(void); /* No memory allocate available. */
	void	(*late_init)(void); /* Yes, can allocate memory. */
#define IOMMU_FINISH_IF_DETECTED (1<<0)
#define IOMMU_DETECTED		 (1<<1)
	int		flags;
};
```

## Intel IOMMU初始化过程


全局变量：
int dmar_table_initialized：表示dmar表是否初始化，如果parse_dmar_table成功就设为1；
struct acpi_table_header dmar_tbl：dmar表的地址


内核启动后从ACPI中获取DMAR table，解析ACPI表中两项：DRHD,DMA Engine Reporting Structure 和 RMRR, Reserved memory Region Reporting Structure。调用`detect_intel_iommu`，它只检测了类型为`ACPI_DMAR_TYPE_HARDWARE_UNIT`的数据，也就是IOMMU硬件单元，还尝试读了IOMMU硬件的capability和extended capability，如果都成功说明IOMMU可以初始化，设置给x86_init.iommu.iommu_init = intel_iommu_init，在内存管理模块初始化后再进行调用初始化相关内存管理模块。初始化iommu内存管理数据在`rootfs_initcall(pci_iommu_init)`中，在pci子系统初始化后执行。

detect_intel_iommu执行时还没有memory allocator，所以干的活很简单，但intel_iommu_init执行时memory allocator已经形成，所以intel_iommu_init就大量分配内存建立iommu的数据结构，主要是`struct dmar_drhd_unit`和`struct intel_iommu`。

detect_intel_iommu函数主要作用就是获取dmar acpi表，然后解析表里面的相关信息如果表里面remapping structure为drhd则通过cb函数来验证dma remapping hardware unit是否可用，具体是`dmar_validate_one_dh`， 然后指定iommu_init函数入口为intel_iommu_init。

```C
int __init detect_intel_iommu(void)
{
        int ret;
        struct dmar_res_callback validate_drhd_cb = {
                .cb[ACPI_DMAR_TYPE_HARDWARE_UNIT] = &dmar_validate_one_drhd,
                .ignore_unhandled = true,
        };

        down_write(&dmar_global_lock);
        ret = dmar_table_detect();
        if (ret)
                ret = !dmar_walk_dmar_table((struct acpi_table_dmar *)dmar_tbl,
                                            &validate_drhd_cb);
        if (ret && !no_iommu && !iommu_detected && !dmar_disabled) {
                iommu_detected = 1;
                /* Make sure ACS will be enabled */
                pci_request_acs(); //?
        }

#ifdef CONFIG_X86
       if (!ret) {
            x86_init.iommu.iommu_init = intel_iommu_init;
            x86_platform.iommu_shutdown = intel_iommu_shutdown;
        }
#endif

       if (dmar_tbl) {
            acpi_put_table(dmar_tbl);
            dmar_tbl = NULL;
        }
        up_write(&dmar_global_lock);

        return ret ? 1 : -ENODEV;
}
```

intel_iommu_init: 分配内存建立iommu的数据结构，主要是`struct dmar_drhd_unit`和`struct intel_iommu`。
1. dmar_table_init：解析dmar表中不同类型的remapping structures。
2. dmar_dev_scope_init()： 主要是初始化每个dmar unit(iommu硬件)下挂载的设备。
3. dmar_register_bus_notifier()
4. intel_iommu_debugfs_init()
5. init_no_remapping_devices();
6. init_dmars()：对dma remapping 做一些初始化的工作。具体的比如把每个drhd关联到struct intel_iommu，假设系统当中如果有n个dma硬件则系统会创建一个大小为n* sizeof(struct intel_iommu*)的g_iommu数组，
7. init_iommu_pm_ops()

iommu_init_mempool：为iova, iommu_dmoain, devinfo创建内存池。

dmar_table_init：调用`parse_dmar_table`解析dmar表中不同类型的remapping structures,解析成功并有IOMMU设备设置全局变量`dmar_table_initialized`为1。当前IOMMU设备类型支持5类，它们分别是HARDWARE_UNIT，RESERVED_MEMORY，ROOT_ATS ，HARDWARE_AFFINITY，NAMESPACE, SATC。其中hardware_unit指的就是iommu硬件，而ATS指的是pcie 的一个重要feature这里我们也不细说。我们重点讲一下RESERVED_MEMORY和 HARDWARE_AFFINITY。HARDWARE_AFFINITY具体指的是Remapping Hardware Status Affinity(RHSA)信息，主要因为在numa架构下iommu硬件可能会跨node，而通过RHSA信息来报告cpu和内存跟每个iommu硬件的亲和性，从而 保证了iommu硬件的perfomace。RESERVED_MEMORY 类型的structures描述的是专门给一些设备预留的DMA内存信息，RMRR 的内存区域必须是4k对齐的，原则上RMRR只针对一些legacy设备比如USB，UMA graphics等设备来使用，而其他设备类型一般不建议使用RMRR。

```C
├─dmar_table_init
    ├─parse_dmar_table
    |   ├─dmar_table_detect
    |       |-acpi_get_table //在acpi表中查找"DMAR"开头的表。找到放到全局变量dmar_tbl中。 
    |   |-tboot_get_dmar_table(dmar_tbl) // ?tboot?
    |   └─dmar_walk_remapping_entries
    |       ├─dmar_parse_one_drhd
    |       |  ├─dmar_find_dmaru
    |       |  ├─dmar_alloc_dev_scope//分配好多空内存
    |       |  ├─alloc_iommu
    |       |  |   |─map_iommu
    |       |  |─dmar_register_drhd_unit
    |       ├─dmar_parse_one_rmrr
    |       ├─dmar_parse_one_atsr
    |       ├─dmar_parse_one_rhsa
    |       |─dmar_parse_one_andd
    |       |-dmar_parse_one_satc
```

```C
struct dmar_res_callback cb = {
  .print_entry = true,
  .ignore_unhandled = true,
  .arg[ACPI_DMAR_TYPE_HARDWARE_UNIT] = &drhd_count,
  .cb[ACPI_DMAR_TYPE_HARDWARE_UNIT] = &dmar_parse_one_drhd,
  .cb[ACPI_DMAR_TYPE_RESERVED_MEMORY] = &dmar_parse_one_rmrr,
  .cb[ACPI_DMAR_TYPE_ROOT_ATS] = &dmar_parse_one_atsr,
  .cb[ACPI_DMAR_TYPE_HARDWARE_AFFINITY] = &dmar_parse_one_rhsa,
  .cb[ACPI_DMAR_TYPE_NAMESPACE] = &dmar_parse_one_andd,
};
  
```

dmar_dev_scope_init: 这个函数里面主要是初始化每个dmar unit(iommu硬件)下挂载的设备。

dmar_init_reserved_ranges: 这个函数主要是reserved一些iova ranges防止被其他设备dma，比如ioapic的iova地址范围还有就是各个pci/pcie设备的mmio地址空间。

init_no_remapping_devices: 这个函数的主要作用是忽略下面没有设备或者只有gfx设备(显卡驱动不会调用dma相关的api进行相关的操作)的dmar unit硬件

init_dmars: 这个函数的作用从它的名字也基本能看出来就是对dma remapping 做一些初始化的工作。具体的比如把每个drhd关联到struct intel_iommu，假设系统当中如果有n个dma硬件则系统会创建一个大小为n* sizeof(struct intel_iommu*)的g_iommu数组，首先通过intel_iommu_init_qi 为每个iommu初始化Invalidation Translation Caches 机制，目前有两种一种是Register-based invalidation interface，另外一种是Queued invalidation interface；其次通过iommu_init_domains 为每个intel_iommu分配domain_ids和dmar_domains，同时为每个intel_iommu分配root_entry即root_table的基址(图6)，然后写到基址寄存器RTADDR_REG当中。


hw_pass_through &iommu_pass_through: 前者表示iommu硬件是否有直通能力是通过读iommu硬件的ecap来获取的，而后者是通过kernel的cmdline人为设置iommu=pt来实现的。如果设置为pt，则iommu_pass_through设置为1，相应的iommu_identify_mapping会设置为IDENTMAP_ALL。在这种场景下，系统会通过si_domain_init创建一个全局的dmar_domain(你可以理解它存储了所有的图6当中address translation的页表)，si表示的是static即静态的，之所以说是静态的是因为si_domain会把每个node上的内存提前建立好iova到hpa的mapping。 然后再把每个iommu下面挂着的设备跟si_domain关联起来，具体做法是说先找到这个设备所属的iommu在驱动层的表现就是找到所属的struct intel_iommu结构体，然后通过这个设备所在的bus号找到其在root_table的位置，再通过devfn创建相对应的context_entry，然后把si_dmain的pgd设置为contex_entry的基址，具体见iommu_prepare_static_identity_mapping(hw_pass_through)函数。

```C
for_each_online_node(nid) {
  unsigned long start_pfn, end_pfn;
  int i;

  for_each_mem_pfn_range(i, nid, &start_pfn, &end_pfn, NULL) {
          ret = iommu_domain_identity_map(si_domain,
                          PFN_PHYS(start_pfn), PFN_PHYS(end_pfn));
          if (ret)
                  return ret;
  }
}
```

bus_set_iommu(&pci_bus_type, &intel_iommu_ops):这个函数主要是为pci_bus设置intel_iommu_ops，并通过iommu_bus_init做一些初化的工作。具体的工作包括为bus注册通知回调函数，还有就是通过add_iommu_group给每个设备创建iommu_group，一个iommu_group可以对一个设备也可以对应多个设备，至于具体是如何分组我们看一下具体的函数实现，这段逻辑最终会调用到pci_device_group函数。这个函数的核心逻辑在于pci_acs_path_enabled，简单来说如果是pcie的设备则检查该设备到root complex的路径上如果都开启了ACS则这个设备就单独成一个iommu_group，如果不是则找到它的alias group就行了比如如果这个是传统的pci bus(没有pcie这些ACS的特性)则这个pci bus下面的所有设备就组合成一个iommu_group。

```C
struct iommu_group *pci_device_group(struct device *dev)
{
    struct pci_dev *pdev = to_pci_dev(dev);

    /*
     * Find the upstream DMA alias for the device.  A device must not
     * be aliased due to topology in order to have its own IOMMU group.
     * If we find an alias along the way that already belongs to a
     * group, use it.
     */  
    if (pci_for_each_dma_alias(pdev, get_pci_alias_or_group, &data))
        return data.group;

    /*
     * Continue upstream from the point of minimum IOMMU granularity
     * due to aliases to the point where devices are protected from
     * peer-to-peer DMA by PCI ACS.  Again, if we find an existing
     * group, use it.
  */
 for (bus = pdev->bus; !pci_is_root_bus(bus); bus = bus->parent) {
  if (!bus->self)
   continue;

  if (pci_acs_path_enabled(bus->self, NULL, REQ_ACS_FLAGS))
   break;

  pdev = bus->self;
  group = iommu_group_get(&pdev->dev);
  if (group)
   return group;
   }

    /*   
     * Look for existing groups on device aliases.  If we alias another
     * device or another device aliases us, use the same group.
     */
    group = get_pci_alias_group(pdev, (unsigned long *)devfns);
    if (group)
        return group;

    /*   
     * Look for existing groups on non-isolated functions on the same
     * slot and aliases of those funcions, if any.  No need to clear
     * the search bitmap, the tested devfns are still valid.
     */
    group = get_pci_function_alias_group(pdev, (unsigned long *)devfns);
    if (group)
        return group;

 return iommu_group_alloc();
}
```

```c
struct list_head dmar_drhd_units;
static LIST_HEAD(dmar_rmrr_units);
pci_iommu_init
  └─intel_iommu_init
      ├─dmar_table_init
      ├─parse_dmar_table
      |   ├─dmar_table_detect
      |   └─dmar_walk_remapping_entries
      |       ├─dmar_parse_one_drhd
      |       |  ├─dmar_find_dmaru
      |       |  ├─dmar_alloc_dev_scope//分配好多空内存
      |       |  ├─alloc_iommu
      |       |  |   └─map_iommu
      |       |  └─dmar_register_drhd_unit
      |       ├─dmar_parse_one_rmrr
      |       ├─dmar_parse_one_atsr
      |       ├─dmar_parse_one_rhsa
      |       └─dmar_parse_one_andd
      ├─dmar_dev_scope_init
      | ├─dmar_acpi_dev_scope_init
      | |     └─for(dev_scope_num in acpi table)
      | |           ├─acpi_bus_get_device
      | |           └─dmar_acpi_insert_dev_scope//给上面注释中指的内存空间中写dev/bus
      | └─for_each_pci_dev(dev)//把非acpi上报的dev上搞到iommu中来
      |     ├─dmar_alloc_pci_notify_info
      |     ├─dmar_pci_bus_add_dev
      |     |   ├─for_each_drhd_unit//找到dev的hrhd然后加入
      |     |   |    └─dmar_insert_dev_scope
      |     |   ├─dmar_iommu_notify_scope_dev
      |     |   └─intel_irq_remap_add_device
      |     └─dmar_free_pci_notify_info
      ├─init_dmars//后面单独分析
      ├─bus_set_iommu//后面单独分析
      └─for_each_iommu
             └─iommu_enable_translation
```
单独分析init_dmars，有点复杂。
```c
init_dmars
  ├─for_each_iommu
  |   ├─intel_iommu_init_qi//软件给硬件通过这块内存提交任务，硬件清自己的iotlb缓存
  |   |   └─dmar_enable_qi
  |   |       └─__dmar_enable_qi//写硬件寄存器
  |   ├─iommu_init_domains//分配了很多struct dmar_domain
  |   └─iommu_alloc_root_entry
  ├─for_each_active_iommu
  |   ├─iommu_flush_write_buffer
  |   └─iommu_set_root_entry//写硬件寄存器
  ├─si_domain_init
  |   ├─alloc_domain(DOMAIN_FLAG_STATIC_IDENTITY)//额外创建一个domain
  |   ├─for_each_online_node//在这个domain中dma地址和物理地址一一对应
  |   |   └─for_each_mem_pfn_range
  |   |       └─iommu_domain_identity_map
  |   |           └─__domain_mapping
  |   └─for_each_rmrr_units//rmrr内存在这个domain中一一对应
  |      └─for_each_active_dev_scope
  |           └─iommu_domain_identity_map
  └─for_each_iommu
      ├─iommu_flush_write_buffer
      └─dmar_set_interrupt//iommu硬件自己的中断
          ├─dmar_alloc_hwirq
          └─request_irq(irq, dmar_fault)
```
有四种domain，init_dmars中用到了IOMMU_DOMAIN_IDENTITY，这个类型的domain只能有一个，kvm和dpdk会用到IOMMU_DOMAIN_UNMANAGED，一个qemu或者一个dpdk进程一个domain。IOMMU_DOMAIN_BLOCKED和IOMMU_DOMAIN_DMA是内核用到，它和iommu group有关系，一个group对应一个domain，一个group有可能有多个dev，这个和pci硬件结构有关系，详见函数pci_device_group。
```c
/*
 * This are the possible domain-types
 *
 *	IOMMU_DOMAIN_BLOCKED	- All DMA is blocked, can be used to isolate  devices
 *	IOMMU_DOMAIN_IDENTITY	- DMA addresses are system physical addresses
 *	IOMMU_DOMAIN_UNMANAGED	- DMA mappings managed by IOMMU-API user, used for VMs
 *	IOMMU_DOMAIN_DMA	- Internally used for DMA-API implementations. This flag allows IOMMU drivers to implement certain optimizations for these domains
 */
```
单独分析bus_set_iommu，这个函数中有个default domain，如果内核参数iommu=pt，这个default domain就是唯一类型为IOMMU_DOMAIN_IDENTITY的si，如果内核参数iommu=nopt就是类型为IOMMU_DOMAIN_DMA的domain，内核参数没有iommu，默认为IOMMU_DOMAIN_IDENTITY。
```c
bus_set_iommu
  └─iommu_bus_init
      ├─bus_iommu_probe//处理bus上的设备
      |   ├─bus_for_each_dev//给dev分配group，
      |   |   └─probe_iommu_group
      |   |        └─__iommu_probe_device
      |   |             ├─intel_iommu_probe_device
      |   |             └─iommu_group_get_for_dev
      |   |                   └─pci_device_group//真正决定group的函数
      |   └─for_each_group
      |        ├─probe_alloc_default_domain//给内核管理的dev分配default domain
      |        ├─iommu_group_create_direct_mappings//对系统保留区分建立mapping，如dev和ioapic的关系
      |        |   └─iommu_create_device_direct_mappings
      |        |       ├─list_for_each_entry
      |        |       |   ├─iommu_iova_to_phys
      |        |       |   └─iommu_map
      |        |       └─iommu_flush_iotlb_all
      |        ├─__iommu_group_dma_attach
      |        |     └─dmar_insert_one_dev_info//创建这个dev在IOMMU中的转换表
      |        └─__iommu_group_dma_finalize
      |              └─intel_iommu_probe_finalize
      |                  └─iommu_dma_init_domain//给dev分配iova并且flush到硬件上
      └─bus_register_notifier(iommu_bus_notifier)//用于处理hotplug的设备
```
初始化工作准备了设备动态运行时要用到的数据和函数，后面就得分析设备动态运行时做了什么操作，调用了哪些函数。


- struct inte_iommu：iommu硬件在驱动层所对应的概念
- struct iommu_group: 一个group下面可以对应多个或者一个硬件设备
- struct dmar_domain: dmar_domain里面存储的是iova->hpa的转换页表，一个dmar_domain可以为多个或者一个设备服务。
- struct iommu_domain: 一个iommu_domain里面可以有多个iommu_group，然后每个iommu_group通过iommu_domain最终找到dmar_domain进行转换。



REF：
https://zhuanlan.zhihu.com/p/492749752
https://zhuanlan.zhihu.com/p/479963917

https://zhuanlan.zhihu.com/p/479988393
https://www.eet-china.com/mp/a118067.html

https://www.owalle.com/2021/11/01/iommu-code/