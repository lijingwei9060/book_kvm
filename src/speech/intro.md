# 概念


AEC（声学回声抑制）: 播放的远端语音，通过直接传输或者反射被mic采集成为近端声音一部分，这部分信号叫echo（回声），所以从echo形成的原理来看，echo应该是近端采集信号中与远端信号相关的信号，也就是远端信号延时（时移）和衰减（权重）组合。AEC（Acoustic Echo Chancellor）亦即声学回声消除，其基本思想就是利用自适应滤波对设备回声系统进行辨识,也就是找出刚才说的时移和权重信息，当系统稳定了，就可以通过远端通过加权组合得到echo，然后近端信号减去echo即为需要的近端语音信号。webrtc中采用的是基于分段频域NLMS（归一化最小均方）自适应滤波算法，可参考论文Partioned block frequeney domain adaptive filter(PBFDAF)。详细可参考博客[语音自适应回声消除（AEC）算法](https://blog.csdn.net/shichaog/article/details/71152743)。我理解，aec应该需要一个DTD（Double Talk Detect），在没有近端语音的时候，也就是此时mic采集到的信号是回声（可能有噪声），这时候自适应滤波的理想信号就是近端信号，可以对自适应滤波器机型参数更新；当没有远端语音的时候，不做处理；当近端和远端都有语音的时候，利用系数进行滤波。但是在我分析webrtc aec的源码时，并没有看到DTD相关源码，不知道是不是我理解有误（望博友指教）。webrtc自适应滤波结束后，还进行了NLP（非线性处理）滤波，将残余echo消除（这部分代码也不是很明确，大概是将比较弱的信号剔除）。

NS（噪音抑制,Noise Suppression）; 降噪就是从给定的观察到数据里面，估计出噪声，然后将噪声部分剔除。这有点像两种墨水混合在一起，要分开他们的意思，难度比较大，既然要分开他们，必须有可区分特征可用才能区分，webrtc用的区分特征是似然比、频谱平坦度和频谱模板差异度，通过映射函数将特征转换成概率模型。因为信号短时平稳，假设语音和噪声都符合高斯分布，对信号进行分位数初始噪声估计（这一块算法不是很清楚），然后可以得到后验信噪比，通过DD决策，得到先验信噪比，将以上信息组合，利用贝叶斯方程，可以计算出语音和噪声的后验概率，然后利用后验对噪声进行更新，这样估计出噪声，再用维纳滤波器将噪声去除。不管是VAD还是NS都有对噪声的初始假设，也就是是噪声的先验概率，所以算法性能受限于此（VAD是固定初始化，NS是分位数估计初始化，不知道理解正确不，忘博友指正）。详细可参考[WebRTC之noise suppression算法](https://blog.csdn.net/shichaog/article/details/52514816)。

VAD（语活检测,Voice Activity Detect）语活检测就是检测信号中是否有语音存在。webrtc用的是混合高斯模型对语音和噪声进行建模，通过模型计算出语音和噪声的概率，然后通过似然比来对是否有语音进行判断。VAD检测用的是能量信息，将信号4khz以下部分分成六个子带，并计算能量，对每一个子带能量进行建模。每个模型中分为语音和噪声模型，分别由两个高斯分布组成，所以一共有24高斯分布（24组均值和方差），对每个模型参数具有初始化值。计算中，分为局部和全局似然比，如果某一个子带似然比大于阈值，就认为有语音，或者似然比之和大于阈值也认为有语音。模型更新采用的是梯度下降法。更详细可参考[WebRTC之VAD算法和高斯混合模型（GMM model）](https://blog.csdn.net/shichaog/article/details/52399354)以及[梯度下降法（gradient descent）更新参数](https://blog.csdn.net/book_bbyuan/article/details/78843240)。

CNG（舒适噪声,Comfortable Noise Generate）舒适噪声生成，这个主要用在通信没有声音的时候，产生一个舒适噪声，既可以降低带宽，有不能让对方感觉已经断线，平时微信语音对方不说话的时候里面听到的斯斯生就是舒适噪声，舒适噪声生成算法可参考博客[舒适噪声生成算法及其实现](https://blog.csdn.net/shichaog/article/details/80210194)。

AGC（自增益控制,Automatic Gain Control）就是对信号的幅度自动增益控制，根据信号的快慢包络，得到对应的增益，然后对信号进行增益处理。由于人耳对不同频率增益敏感度不一样，在处理的时候需要基于等响曲线的非线性增益表来获得不同频点的增益。

远端语音信号：被远端麦克风采集的信号（说话人语音），也等于近端扬声器播放的语音，也称为参考语音
近端语音信号：近端说话人语音信号
近端麦克风接收的语音信号：近端扬声器播放的声音+在房间多径反射的语音+近端说话人的语音
远端混合回声信号：整个对话过程中，近端麦克风接收到的信号有近端说话人语音信号和近端扬声器播放的远端说话人语音，这样叠加的语音信号通过传输线路传到远端扬声器播放导致远端人听到自己刚刚检测出的语音信号，即所谓的回声。

声学回声信号根据传输途径的差别可以分别直接回声信号和间接回声信号。
- 直接回声（线性回声）：近端扬声器将语音信号播放出来后，被近端麦克风直接采集后得到的回声；直接回声不受环境的印象，与扬声器到麦克风的距离及位置有很大的关系，因此直接回声是一种线性信号。
- 间接回声（非线性回声）：近端扬声器将语音信号播放出来后，语音信号经过复杂多变的墙面反射后由近端麦克风采集；间接回声的大小与房间环境、物品摆放以及墙面吸引系数等等因素有关，因此间接回声是一种非线性信号。

一个完整的回声消除系统，包含以下几个模块：
- 时延估计（Time Delay Estimation, TDE） 模块
- (线性)回声消除（Linear Acoustic  Echo Cancellation, AEC） 模块
- 双讲检测（Double-Talk Detect, DTD） 模块
- 非线性残余声学回声抑制（Residual Acoustic Echo Suppression, RAES） 模块

## 回声时延估计(Time Delay Estimation, TDE)

Bastiaan的算法： 
1. 1表示有说话音，0表示无说话音(静音或者很弱的声音)
2. p表示时间间隔，q表示频带. fft后的频率分为32个频带，用32bit表示。
3. 远端信号x(t): 对输入信号x加窗(如汉宁窗)后的功率谱用Xw(p,q)来表示，对每个频带中的功率谱设定一个门限 Xw(p,q)_threshold, 如果 Xw(p,q)  >= Xw(p,q)_threshold  ,   则Xw(p,q) =1；如果 Xw(p,q) <    Xw(p,q)_threshold  ,   则Xw(p,q) =0；75个32位binary_far_history的数组存放历史远端参考信号
4. 近端信号y(t): 对于信号y(t),加窗信号功率谱Yw(p,q)和门限Yw(p,q)_threshold，如果 Yw(p,q) >= Yw(p,q)_threshold   ,   则Yw(p,q) =1；如果 Yw(p,q) < Yw(p,q)_threshold ,        则Yw(p,q) =0；16个32位binary_near_history的数组存放历史近端参考信号，最近的值都放在下标为0的数组中
5. 时延估计： 使用binary_near_history[15] 的32位bit与binary_far_history数组中75个32位bit分别按位异或，得到75个32位比特数据，32位bit的物理意义是近似 地使用功率谱来统计两帧信号的相关性。统计32位结果中的1的个数存于bit_counts中，接下来用对bit_counts进行平滑防止延时突变，得 到mean_bit_count,可以看出  mean_bit_count 越小，则表明近端数据与该帧的远端数据越吻合，两者的时延越接近所需要的延时数值，用 value_best_candidate表示。剩下的工作是对边界数值进行保护，如果value_best_candidate接近最差延时(预设)， 则表明数值不可靠，这时不更新延时数据；如果数据可靠，则进一步使用一阶markvo模型，比照上一次时延数据确定本次最终的更新时延 last_delay。


## 回声消除常用算法

1. x(n)为远端语音
2. 经过未知的回声路径w(n)，得到远端回声语音y(n)=x(n)*w(n)
3. 近端语音s(n)
4. 期望信号d(n) = y(n) + s(n)
5. x(n)通过自适应滤波器$\hat{w}(n)$得到估计的回声信号$\hat{y}(n)$，并与期望信号d(n)相减得到误差信号$e(n)=d(n)-\hat{y}(n)$，误差信号的值越小说明自适应滤波算法所估计的回声路径就越接近实际的回声路径。

自适应滤波器： 求$\hat{w}(n)$逼近真是的w(n), 使得误差e(n)最小。 解题算法： LMS、NLMS、FDAF频域自适应滤波器

### LMS最小均方
=> 求使得$\vert e(n) \vert ^2$最小的$\hat{w}(n)$, 其中：$e(n) = d(n) - \hat{w}(n)$
$$
\begin{align*}
  w(n+1) &= w(n) - \mu \frac{\partial e(n)^2}{\partial w} \\
         &= w(n) - 2\mu e(n)\frac{\partial(d(n)-\hat{w}*x(n))}{\partial w} \\
         &= w(n) + 2\mu e(n)x(n)
\end{align*}
$$

$\mu$为固定步长因子，它的大小决定了算法的手链盒稳定性能，为了保证稳态收敛，取值范围为$0 \lt \mu \lt \frac{2}{\sum_{i=1}^Nx(i)^2}$

1. 滤波器输出$\hat{y}(n)=\sum_{i=1}^N\hat{w}(n)x(n-i)=\hat{w}(n)x(n)$， 初始回声路径为0，N为什么(步长？)，x为什么(声音振幅?)
2. 误差估计$e(n)=d(n)-\hat{y}(n)$
3. FIR向量的抽头权值更新，以准备下一次迭代$\hat{w}(n+1)=\hat{w}(n)+2\mu e(n)x(n)$


LMS算法需要2N加法和2N+1乘法。

### NLMS归一化最小均方自适应算法

归一化最小均方（NLMS）算法是LMS算法的一个扩展，利用可变的步长因子代替固定的步长因子，就得到了NLMS算法，它通过计算最大步长值$\mu$绕过了这个问题, $\mu= \frac{1}{x^T(n)x(n)}$。

NLMS算法迭代过程： $\hat{w}(n+1)=\hat{w}(n)+\mu(n)e(n)x(n)=\hat{w}(n)+\frac{1}{x^T(n)x(n)}e(n)x(n)$。


NLMS比传统LMS算法复杂度略高，但收敛速度明显加快;LMS/NLMS性能差于AP和RLS算法。

### rls滤波器
- $\delta$ 较小的初始值
- $P(0) = \delta I$, 初始值p+1阶单元矩阵
- $\lambda$遗忘因子，接近于1

$$
\begin{align*}
  e(n)&=d(n)-x^T(n)w(n-1) \\
  g(n)&=P(n-1)x(n)\{\lambda+x^T(n)P(n-1)x(n)\}^{-1} \\
  P(n)&=\lambda^{-1}P(n-1)-g(n)x^T(n)\lambda^{-1}P(n-1) \\
  w(n)&=w(n-1) + e(n)g(n)
\end{align*}
$$

### 卡尔曼滤波器(Kalman Filter)
- H初始为0
- Q
- R
- P

$$
\begin{align*}
  E_n &= D_n - X^T_nh_{n-1} \\
  R_n &= \beta R_{n-1} + (1-\beta)E_n^2 \\
  P_n^- &= P_{n-1} + Q \\
  K_n &= P_n^-X_n(X_nP_n^-X_n^T+R)^{-1} \\
  \hat{x}_n &= \hat{x}_{n-1} + K_nE_n \\
  P_n &= (I-K_nX_n^T)P_n^-
\end{align*}
$$

### 分段块频域自适应滤波算法(Frequency Domain Block NLMS Adaptive Filter)
- 通过OLS的方法进行分段然后使用FFT快速计算卷积 得到频域自适应滤波器

## NLP（非线性滤波）

webrtc采用了维纳滤波器。此处只给出传递函数的表达式，设估计的语音信号的功率谱为Ps(w)，噪声信号的功率谱为Pn(w)，则滤波器的传递函数为H(w)=Ps(w)/(Ps(w)+Pn(w))。

## CNG(舒适噪声产生）

webrtc采用的舒适噪声生成器比较简单，首先生成在[0 ,1 ]上均匀分布的随机噪声矩阵，再用噪声的功率谱开方后去调制噪声的幅度。