
# 内存跟踪
在使用qemu的时候提供了热迁移的功能，就是在虚拟机不关机，服务正在运行的时候将虚拟机迁移到另外一台服务器上。很多硬件问题，可以通过这个中方提前进行预处理，热迁移大法好。当然迁移故障率很高。

热迁移的时候主要就是跟踪变化的内存，然后堆内存进行同步。可以设想，跟踪内存肯定要一个地方保存变化的位图信息，哪些内存页面发生了变化；有个触发机制，一旦在vmx-non root模式下有程序写入页面会触发位图标志位变更；标志位位图清理方法，用户态在消费这个标志位后应该有能力进行清理；再加一个api提供哪些位图发生了变化，就可以实现一个内存变化的跟踪。 触发的机制肯定是在vmx root模式，guest里面是不可能去维护位图信息，这个位图信息必然在vmx root模式下，也就是记录标志位需要vm-exit。

在内存虚拟化里面，存在shadow page table entry保留gpn到vpn的影子页表，vm-exit的时候将标志位记录在这个地方，ste的后面12位就可以保留这个信息。
Intel自然不会放过这个优化的机会， 增加了PML（page manification logging）功能，开辟一个4K的内存页面保存PML buffer，保存512个8字节地址，如果一个gpa发生了变化就将对齐的gpa插入这个记录中。同时在vmcs vm-execution增加“PML enable”和“PML Address”设置PML开启标志位和PML buffer物理地址，在guest state area增加了PML index指向vm-exit时使用的PML buffer中entry的index。guest os读写内存 经过EPT转换的时候直接修改PML buffer，不发生vm-exit。PML buffer只能保存512个记录，如果超过将发生page-modification log-full event，然后触发VMExit。

# 硬件加持大法
硬件大法就是在EPT的基础上增加PML跟踪功能，脏页的置位不需要vm-exit，由EPT硬件进行写入PML Buffer, 从511 index递减使用。在vmexit的时候将PML index写入到vmcs guest state area区域，vm-entry的时候直接加载，PML 满了会发出PML full event， kvm可以消费这些数据。所以 PML完整的实现的脏页管理的硬件化，减少了vm-exit，提升了性能。

脏页标志位的清零动作是在PML之外，也就是需要KVM或者qemu完成。

## PML 脏页跟踪
- struct vcpu_vmx: struct page *pml_pg, 是PML buffer，指向VMCS Vm-Execution控制域PML Address字段。
- struct kvm_dirty_log： 为了用户态程序交互内存dirty信息，KVM_GET_DIRTY_LOG

脏页配置启用
1. vmx_x86_ops.hardware_setup-> setup_vmcs_config 设置SECONDARY_EXEC_ENABLE_PML标识使能PML
2. vmx_create_vcpu -> vmx_vcpu_setup,分配一个物理页给pml_pg用作PML Buffer,将分配好的PML Buffer地址写入VMCS的对应区域，同时初始化PMLIndex为511 。
3. vmx_slot_enable_log_dirty: 
   1. kvm_mmu_slot_leaf_clear_dirty:清零Dirty位，slot包含的所有物理页的spte的Dirty位清零，这里需要根据gfn找到指向该gfn对应页的spte，反向映射数组rmap就派上了用场。
   2. kvm_mmu_slot_largepage_remove_write_access: 物理页开启写保护：除了清零页表项的Dirty位，记录脏页还需要开启页的写保护，在脏页记录的过程中，所有slot包含的物理页变成只读，当CPU写访问这个页时，发生缺页异常，kvm会重新分配一个新的页给CPU。

在没有PML机制的情况下，使用页只读的方式记录脏页，判断两种情况，分别处理：
1. 首次迭代时位图都标记为1，不需要标记4k小页，但需要标记2M的大页为只读，这样kvm在处理虚机大页访问异常时会将其拆分成小页。
2. 对于其它轮次的迭代，需要将所有4k页的页表项都标记为只读`kvm_mmu_slot_remove_write_access` 


获取脏页的流程，实际上也分为了两个步骤，第一步是拷贝dirty bitmap，第二步是清零脏页的标志, 两个ioctl命令字，KVM_GET_DIRTY_LOG和KVM_CLEAR_DIRTY_LOG。
1. 获取脏页bitmap
```C
kvm_vm_ioctl
    case KVM_GET_DIRTY_LOG: 
        kvm_vm_ioctl_get_dirty_log
            kvm_get_dirty_log_protect 	
                slots = __kvm_memslots(kvm, as_id);
                memslot = id_to_memslot(slots, id);
                /* x86架构使用PML机制获取脏页 */
                kvm_arch_sync_dirty_log
                    kvm_x86_ops.flush_log_dirty <=>   vmx_flush_log_dirty
                        /* kick每个vcpu让其vmexit，这样在vmexit的路径上可以更新pml buffer */
                        kvm_flush_pml_buffers
                            kvm_vcpu_kick
                /* dirty bitmap获取到之后，如果使能了KVM_CAP_MANUAL_DIRTY_LOG_PROTECT
                 * 特性，则跳过清零脏页的步骤，直接拷贝dirty bitmap */
              	if (kvm->manual_dirty_log_protect) {
              	    dirty_bitmap_buffer = dirty_bitmap;
              	} else {
              		/* 获取mmu_lock锁，修改页表，将对应位清零 */
					spin_lock(&kvm->mmu_lock);
						kvm_arch_mmu_enable_log_dirty_pt_masked(kvm, memslot,
													offset, mask);

					spin_unlock(&kvm->mmu_lock);
				}
                kvm_arch_flush_remote_tlbs_memslot
                /* 拷贝dirty bitmap到用户态 */
                copy_to_user(log->dirty_bitmap, dirty_bitmap_buffer, n)                   
```
2. 使用PML机制获取dirty bitmap时，只是将所有vcpu kick了一遍，具体的更新操作在vcpu从guest退出的路径上完成，简单分析下：
```C
vmx_handle_exit
	if (enable_pml)
		vmx_flush_pml_buffer(vcpu);
			/* 遍历PML buffer的entry，将其更新到内存页所属的slot的dirty bitmap */
			for (; pml_idx < PML_ENTITY_NUM; pml_idx++) {
				gpa = pml_buf[pml_idx];
				kvm_vcpu_mark_page_dirty(vcpu, gpa >> PAGE_SHIFT);
					memslot = kvm_vcpu_gfn_to_memslot(vcpu, gfn);
					mark_page_dirty_in_slot(vcpu->kvm, memslot, gfn);
			}
```
3. 分析一下KVM_CAP_MANUAL_DIRTY_LOG_PROTECT特性下清零脏页的流程：
```C
kvm_vm_ioctl
	case KVM_CLEAR_DIRTY_LOG:
		kvm_vm_ioctl_clear_dirty_log
			kvm_clear_dirty_log_protect
				/* 清零脏页前首先同步之前的脏页信息，使dirty bitmap处于最新状态 */
				kvm_arch_sync_dirty_log
				/* 将最新的脏页信息拷贝到用户态 */
				copy_from_user(dirty_bitmap_buffer, log->dirty_bitmap, n)
				/* 拿mmu_lock锁，准备清零脏页，也就是使能脏页日志 */
				spin_lock(&kvm->mmu_lock)
					kvm_arch_mmu_enable_log_dirty_pt_masked
				spin_unlock(&kvm->mmu_lock)
```
下面两个commit是基于dirty-bitmap机制脏页同步计算脏页速率的commit：
https://github.com/qemu/qemu/commit/4998a37e4bf2bc47f76775e6e6a0cd50bacfb16a
https://github.com/qemu/qemu/commit/826b8bc80cb191557a4ce7cf0e155b436d2d1afa
# 软件模拟大法

